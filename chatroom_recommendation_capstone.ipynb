{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning Nanodegree Capstone\n",
    "# Chat Room Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path will need to be changed pending on where the repo is cloned to\n",
    "os.chdir(os.path.expanduser('~/PycharmProjects/chat-room-recommendation/'))\n",
    "lines = open('cornell-movie-dialogs-corpus/movie_lines.txt','r').read().split('\\n')\n",
    "conv_lines = open('cornell-movie-dialogs-corpus/movie_conversations.txt','r').read().split('\\n')\n",
    "character_metadata = open('cornell-movie-dialogs-corpus/movie_characters_metadata.txt','r').read().split('\\n')\n",
    "movie_metadata = open('cornell-movie-dialogs-corpus/movie_titles_metadata.txt','r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.',\n 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?',\n \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\",\n 'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow',\n \"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\",\n 'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No',\n 'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?',\n 'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\",\n \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use gensim simple pre-processing tool to create a dictionary with keys = movie_id and value = tokenized text of all the lines in the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "movieLines = {}\n",
    "for line in lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 5:\n",
    "        if _line[2] in movieLines: \n",
    "            movieLines[_line[2]] = movieLines.get(_line[2]) + utils.simple_preprocess(_line[4])\n",
    "        else:\n",
    "            movieLines[_line[2]] = utils.simple_preprocess(_line[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct # of movies\n"
     ]
    }
   ],
   "source": [
    "# sanity check that there are the appropriate number of movies in the movieLines dict\n",
    "print \"Correct # of movies\" if len(movieLines) == 617 else \"something went wrong with movieLines dict\"\n",
    "#print movieLines.get(\"m616\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to map each line's id with it's text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2line = {}\n",
    "for line in lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 5:\n",
    "        id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct # of lines\n"
     ]
    }
   ],
   "source": [
    "# sanity check for id2line dict\n",
    "print \"Correct # of lines\" if len(id2line) == 304713 else \"something went wrong with id2line dict\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use gensim simple pre-processing tool to create a dictionary with keys = character_id and value = tokenized text of all conversations for that character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "characterConversations = {}\n",
    "for line in conv_lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 4:\n",
    "        _line[3] = _line[3].strip(\"[]\")\n",
    "        for conv in _line[3].split(\",\"):\n",
    "            conv = conv.replace(\"'\",\"\").replace(\" \", \"\")\n",
    "            if _line[0] in characterConversations:\n",
    "                characterConversations[_line[0]] = characterConversations.get(_line[0]) + \\\n",
    "                                                   utils.simple_preprocess(id2line.get(str(conv)))\n",
    "            else:\n",
    "                characterConversations[_line[0]] = utils.simple_preprocess(id2line.get(str(conv)))\n",
    "\n",
    "            if _line[1] in characterConversations:\n",
    "                characterConversations[_line[1]] = characterConversations.get(_line[1]) + \\\n",
    "                                                   utils.simple_preprocess(id2line.get(str(conv)))\n",
    "            else:\n",
    "                characterConversations[_line[1]] = utils.simple_preprocess(id2line.get(str(conv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct # of characters\n"
     ]
    }
   ],
   "source": [
    "# sanity check that there are the appropriate # of characters in the characterConversation dict\n",
    "print \"Correct # of characters\" if len(characterConversations) == 9035 else \"something went wrong with character dict\"\n",
    "#print characterConversations.get(\"u0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that creates corpus (list of TaggedDocmuments) from dictionaries\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "def create_corpus(dictname):\n",
    "    corpus_list =[]\n",
    "    for key, value in dictname.iteritems():\n",
    "        corpus_list.append(TaggedDocument(value, [int(key[1:])]))\n",
    "    return corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = create_corpus(movieLines)\n",
    "test_corpus = create_corpus(characterConversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct # of movies in train_corpus\nCorrect # of characters in test_corpus\n"
     ]
    }
   ],
   "source": [
    "# sanity check of length of corpus\n",
    "print \"Correct # of movies in train_corpus\" if len(train_corpus) == 617 else \"something went wrong with train_corpus\"\n",
    "print \"Correct # of characters in test_corpus\" if len(test_corpus) == 9035 else \"something went wrong with test_corpus\"\n",
    "# print train_corpus[0].tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a Doc2Vec Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "model = Doc2Vec(size=50, iter=20, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 31s, sys: 3.56 s, total: 8min 35s\nWall time: 3min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44391323"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to be loaded later if needed\n",
    "model.save('/tmp/movie_model.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model if saved during a previous session\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "model = Doc2Vec.load('/tmp/movie_model.doc2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Model\n",
    "To assess the doc2vec model, inferring new vectors for each document of the training corpus, compare the inferred vectors with the training corpus, and then returning the rank of the document based on self-similarity. This approach is pretending as if the training corpus is some new unseen data and then seeing how they compare with the trained model. The expectation is that model will be overfit and so finding similar documents should be very easily. The second ranks will also be tracked for comparison of less similar docutents. (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "first_ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    \n",
    "    rank = [docid for docid, sim in sims].index(train_corpus[doc_id].tags[0])\n",
    "        \n",
    "    ranks.append(rank) \n",
    "    \n",
    "    first_ranks.append(sims[0])\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 615, 1: 2})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Doc2Vec(size=30, iter=20) resulted in Counter({0: 614, 1: 3}) <br/>\n",
    "trained in : CPU times: user 2min 24s, sys: 732 ms, total: 2min 24s Wall time: 54.1 s <br/>\n",
    "* Doc2Vec(size=30, iter=50) resulted in Counter({0: 615, 1: 2})<br/>\n",
    "trained in : CPU times: user 6min, sys: 1.75 s, total: 6min 2s Wall time: 2min 17s\n",
    "* Doc2Vec(size=30, iter=20, min_count=2) resulted in Counter({0: 615, 1: 2}) <br/>\n",
    "trained in : CPU times: user 2min 18s, sys: 712 ms, total: 2min 19s Wall time: 56.6 s\n",
    "* Doc2Vec(size=30, iter=50, min_count=2) resulted in Counter({0: 614, 1: 3}) <br/>\n",
    "trained in : CPU times: user 5min 21s, sys: 1.96 s, total: 5min 23sWall time: 2min\n",
    "* Doc2Vec(size=50, iter=20, min_count=2) resulted in Counter({0: 616, 1: 1})\n",
    "trained in : CPU times: user 2min 21s, sys: 752 ms, total: 2min 22s Wall time: 52 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis\n",
    "Test Doc2Vec model with random lines removed from the training_corpus. The model will be assessed the same way the original training_corpus was assessed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# altlines = open('cornell-movie-dialogs-corpus/movie_lines_mod.txt','r').read().split('\\n')\n",
    "from random import randint\n",
    "from gensim import utils\n",
    "\n",
    "altMovieLines = {}\n",
    "altTotalLines = 0\n",
    "for line in lines:\n",
    "    if randint(0, 9) != 7:\n",
    "        altTotalLines = altTotalLines+1\n",
    "        _line = line.split(' +++$+++ ')\n",
    "        if len(_line) == 5:\n",
    "            if _line[2] in altMovieLines: \n",
    "                altMovieLines[_line[2]] = altMovieLines.get(_line[2]) + utils.simple_preprocess(_line[4])\n",
    "            else:\n",
    "                altMovieLines[_line[2]] = utils.simple_preprocess(_line[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct # of movies\n# of lines were decreased\n274275\n"
     ]
    }
   ],
   "source": [
    "print \"Correct # of movies\" if len(altMovieLines) == 617 else \"something went wrong with movieLines dict\"\n",
    "print \"# of lines were decreased\" if altTotalLines < 304713 else \"something went wrong with id2line dict\"\n",
    "print altTotalLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_train_corpus = create_corpus(altMovieLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_model = Doc2Vec(size=50, iter=20, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_model.build_vocab(alt_train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 11s, sys: 2.87 s, total: 7min 14s\nWall time: 2min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39987989"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time alt_model.train(alt_train_corpus, total_examples=alt_model.corpus_count, epochs=alt_model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_model.save('/tmp/alt_model.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "alt_model = Doc2Vec.load('/tmp/alt_model.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_ranks = []\n",
    "\n",
    "for alt_doc_id in range(len(alt_train_corpus)):\n",
    "\n",
    "    alt_inferred_vector = alt_model.infer_vector(alt_train_corpus[alt_doc_id].words)\n",
    "    alt_sims = alt_model.docvecs.most_similar([alt_inferred_vector], topn=len(model.docvecs))\n",
    "    \n",
    "    alt_rank = [alt_docid for alt_docid, alt_sim in alt_sims].index(alt_train_corpus[alt_doc_id].tags[0])\n",
    "        \n",
    "    alt_ranks.append(alt_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 614, 1: 3})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(alt_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Doc2Vec model with test_corpus (individual character converations) which consist of 9035 different documents.  The model will be assessed the same way the training_corpus was assessed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Doc2Vec(size=50, iter=20, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.build_vocab(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 24s, sys: 10.6 s, total: 17min 35s\nWall time: 7min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89876212"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model2.train(test_corpus, total_examples=model2.corpus_count, epochs=model2.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('/tmp/character_model.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "model2 = Doc2Vec.load('/tmp/character_model.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks2 = []\n",
    "\n",
    "for doc_id2 in range(len(test_corpus)):\n",
    "\n",
    "    inferred_vector2 = model2.infer_vector(test_corpus[doc_id2].words)\n",
    "    sims2 = model2.docvecs.most_similar([inferred_vector2], topn=len(model2.docvecs))\n",
    "    \n",
    "    rank2 = [docid2 for docid2, sim2 in sims2].index(test_corpus[doc_id2].tags[0])\n",
    "        \n",
    "    ranks2.append(rank2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 8238,\n         1: 453,\n         2: 80,\n         3: 45,\n         4: 37,\n         5: 19,\n         6: 24,\n         7: 10,\n         8: 16,\n         9: 13,\n         10: 11,\n         11: 9,\n         12: 7,\n         13: 2,\n         14: 1,\n         15: 5,\n         16: 2,\n         17: 2,\n         18: 1,\n         19: 3,\n         20: 3,\n         21: 3,\n         22: 3,\n         23: 6,\n         24: 1,\n         25: 1,\n         26: 1,\n         27: 2,\n         28: 2,\n         34: 1,\n         35: 1,\n         36: 1,\n         39: 2,\n         41: 1,\n         42: 1,\n         44: 2,\n         46: 1,\n         47: 1,\n         48: 3,\n         50: 1,\n         53: 1,\n         54: 1,\n         59: 1,\n         62: 1,\n         63: 1,\n         76: 1,\n         78: 1,\n         80: 1,\n         86: 1,\n         87: 1,\n         91: 1,\n         92: 2,\n         119: 1,\n         142: 1,\n         143: 1,\n         228: 1,\n         264: 1,\n         441: 1,\n         5017: 1})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(ranks2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get character metadata by id\n",
    "def get_character_metadata(id):\n",
    "    for character in character_metadata:\n",
    "        _character = character.split(' +++$+++ ')\n",
    "        if len(_character) == 6:\n",
    "            if _character[0] == 'u'+str(id):\n",
    "                return _character\n",
    "        \n",
    "           \n",
    "def get_movie_title(id):\n",
    "    for movie in movie_metadata:\n",
    "        _movie = movie.split(' +++$+++ ')\n",
    "        if len(_movie) == 6:\n",
    "            if _movie[0] == 'm'+str(id):\n",
    "                return _movie[1]\n",
    "            \n",
    "            \n",
    "# create def to look up tag doc in corpus by tag id\n",
    "def get_corpus_index(corpus, tag):\n",
    "    for tag_index in range(len(corpus)):\n",
    "        if corpus[tag_index].tags[0] == tag:\n",
    "            return tag_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test of the first movie in the training corpus to ensure that the movie was returned as the most similar document by the model.  The similarity score is also displayed. A random document from the training coupus is aslo selected along and compared with the similarity score of the second most similar document.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie title : star wars\nMovie id : 529\n\nMODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n\nstar wars\n(529, 0.9903789758682251) \n\n----------------------\n\nTrain Document (35): «blast from the past»\n\nTop Document (35, 0.987032413482666): «blast from the past»\n\nSimilar Document (462, 0.7288445234298706): «notting hill»\n\n"
     ]
    }
   ],
   "source": [
    "print('Movie title : {}\\nMovie id : {}\\n'.format(get_movie_title(train_corpus[doc_id].tags[0]), train_corpus[doc_id].tags[0]))\n",
    "print(u'MODEL %s:\\n' % model)\n",
    "\n",
    "print get_movie_title(train_corpus[get_corpus_index(train_corpus, sims[0][0])].tags[0])\n",
    "print sims[0], '\\n\\n----------------------\\n'\n",
    "\n",
    "# Pick a random document from the train corpus and infer a vector from the model\n",
    "rand_train_id = random.randint(0, len(train_corpus))\n",
    "\n",
    "# Inspect the score of the second ranked movie. \n",
    "# The score for the second ranked movie should be much lower then for the top document.\n",
    "print('Train Document ({}): «{}»\\n'.format(rand_train_id, get_movie_title(rand_train_id)))\n",
    "top_id = first_ranks[get_corpus_index(train_corpus, rand_train_id)]\n",
    "print('Top Document {}: «{}»\\n'.format(top_id, get_movie_title(top_id[0])))\n",
    "sim_id = second_ranks[get_corpus_index(train_corpus, rand_train_id)]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, get_movie_title(sim_id[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (193): «star trek: the wrath of khan»\n\nTop Document (193, 0.991351842880249): «star trek: the wrath of khan»\n\nSimilar Document (192, 0.9387556314468384): «star trek iii: the search for spock»\n\n"
     ]
    }
   ],
   "source": [
    "# Movie 193 \"star trek: the wrath of khan\" returns \"star trek iii: the search for spock\" as the second most \n",
    "# similar document. * I guess if you have seen one Star Trek movie you have seen them all... \n",
    "rand_train_id = 193\n",
    "\n",
    "# Inspect the score of the second ranked movie\n",
    "print('Train Document ({}): «{}»\\n'.format(rand_train_id, get_movie_title(rand_train_id)))\n",
    "top_id = first_ranks[get_corpus_index(train_corpus, rand_train_id)]\n",
    "print('Top Document {}: «{}»\\n'.format(top_id, get_movie_title(top_id[0])))\n",
    "sim_id = second_ranks[get_corpus_index(train_corpus, rand_train_id)]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, get_movie_title(sim_id[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "Using the same approach above, we'll infer the vector for a randomly chosen test document (character conversation), and compare the document to the model by eye.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similarity of movie character is from and index \n",
    "def get_source_similarity(sim_list, movie_id):\n",
    "    for sim_index in range(len(sim_list)):\n",
    "        if int(movie_id[1:]) == sim_list[sim_index][0]:\n",
    "            return get_movie_title(sim_list[sim_index][0]), sim_index, sim_list[sim_index][1]\n",
    "        \n",
    "        \n",
    "# print top 5 recommended movies\n",
    "def get_recommended_movies(sim_list):\n",
    "    print('\\nTop 5\\n {}\\n {}\\n {}\\n {}\\n {}\\n'.format(get_movie_title(sim_list[0][0]), get_movie_title(sim_list[1][0]), \n",
    "                                                get_movie_title(sim_list[2][0]), get_movie_title(sim_list[3][0]),\n",
    "                                                get_movie_title(sim_list[4][0])))\n",
    "    \n",
    "    \n",
    "def display_character_similarity(char_id, show_words):\n",
    "    inferred_vector = model.infer_vector(test_corpus[char_id].words)\n",
    "    test_sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    character_metadata = get_character_metadata(char_id)\n",
    "    print('Character : {}\\n ID : {}\\n Movie : {}'.format(character_metadata[1], character_metadata[2], \n",
    "                                                         character_metadata[3]))\n",
    "    if show_words :\n",
    "        print('Test Document ({}): «{}»\\n'.format(char_id, ' '.join(test_corpus[get_corpus_index(test_corpus, char_id)].words)))\n",
    "    print test_sims[:10]\n",
    "    get_recommended_movies(test_sims)\n",
    "    print get_source_similarity(test_sims, character_metadata[2]), '\\n'\n",
    "    \n",
    "    \n",
    "def get_doc2vec_similarity(char_id):\n",
    "    inferred_vector = model.infer_vector(test_corpus[char_id].words)\n",
    "    test_sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "    return test_sims[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : EDDIE\n ID : m80\n Movie : halloween h20: 20 years later\nTest Document (1220): «besides it historically inaccurate what the fuck are you talking about michael meyers never used meat cleaver it was butcher knife who are you the serial killer police what difference does it make it not historically accurate that all another historical inaccuracy would somebody shut this guy up»\n\n[(379, 0.7948283553123474), (602, 0.7291299700737), (460, 0.6810026168823242), (359, 0.6802983283996582), (7, 0.6716787815093994), (148, 0.6479409337043762), (8, 0.6213617920875549), (510, 0.6147223711013794), (601, 0.6047148704528809), (227, 0.6002674698829651)]\n\nTop 5\n halloween\n what women want\n a nightmare on elm street part 2: freddy's revenge\n friday the 13th part iii\n a nightmare on elm street 4: the dream master\n\n('halloween h20: 20 years later', 35, 0.5313981175422668) \n\nCharacter : KERI\n ID : m80\n Movie : halloween h20: 20 years later\nTest Document (1223): «ll be damned do know you mind if we sit down prefer you didn very busy okay then how bout we ask you few questions detective carter think it would be best if you both left might want to stop and think about the safety of your students miss tate never stop thinking about it detective the only way in or out of this school is through that gate and it is secured at all times funny we just drove right in well can assure you it won happen again thanks for your concern goodbye bruce what going on the kids are here to pick out their costumes for the festival better take em to virgil downtown we got dead body in there dead body it amy kramer my god pretty messy parents have already been notified our office has been trying to get hold of you do you know who did this well eddie catero didn show up for work this morning parents say he never came home last night car still missing think eddie had something to do with it doesn look good nothing changed since yesterday or last week or last month the answer still no you re so predictable what the betcha didn predict that sixteen keri should be able to live wherever want and should have son who calls me mom looks like we re both shit out of luck okay you win ll call you mom now can move into the dorms no well dad thinks it okay you re father thinks it okay to run off to cancun with blonde bimbo in halter top somehow his opinion doesn count promise not to run off to cancun forget it the dorms are only fifty feet away you could practically see into my window so what difference does it make my point exactly see we both agree alright was wrong there is big difference between rooming with your buddies and living with your mother and school headmaster took the padlock off your door what more do you want my life is living hell where are you going to the bathroom can do that alone or do you want to watch thought you never ask you re twisted know shit john what the hell were you doing out there nothing you re kidding with that answer right just went for walk it no big deal wrong there are rules in this house and you re going to follow them whether you like it or not or what you re gonna shoot me it an option well maybe if you let me live in the dorms wouldn have to sneak out to spend time with my friends oh so now it my fault just forget it sorry alright it was just stupid joke will sit down you some kind of fugitive or something was trying to get away from someone now you re joking right afraid not you can pick your friends but you can pick your family wait minute slow down you re telling me michael meyers is my uncle yes any other psychotic relatives should know about jason freddy krueger no why didn you tell me was trying to protect you from this where are you going don know he found you didn he get on the bus where molly she not in her room just get on the bus not leaving without her john you can help her now what where is she john oh god no not molly please get on the bus yeah me too keri call me laurie will ya keri laurie how about if just call you mom that would work molly of all the people if can trust my resident assistant then what know really really sorry miss tate please let me keep the job it the only way can afford to stay here okay tell you what you can still be the school but no dance tomorrow night okay thank you linda he killed linda who michael meyers aren they doing terrific job this year looks great it does you okay you seem little off nothing good stiff drink can fix it john isn it it always john still wants to move out he been living out of moving boxes for three months this kid just wants his freedom it not going to happen the tighter you squeeze the harder he ll try to break free oh please you get that out of fortune cookie doesn make it bad advice going into town run few errands before dark need anything box of fortune cookies running out of advice bye will hey you alright what what are you looking at fine just need to lie down there something have to tell you both it going to sound strange what my name hasn always been keri tate it was once laurie strode you re right it does sound strange who michael meyers the serial killer he my brother no will this isn the alcohol talking it the truth can believe this is happening shit happens you just dropped shitload on him give him some time to digest it are you going to leave too never so you re really michael meyers sister yeah do we have to invite him to the wedding not real fan of halloween humor will oh right sorry gonna head back to the office finish up some things can it wait till monday thought maybe we could dance very light of my feet keri you all right we ve got to get these kids out of here ll make sure there no kids left in the dorms»\n\n[(270, 0.655051052570343), (602, 0.6357800364494324), (439, 0.6239815354347229), (366, 0.5800963044166565), (501, 0.5731912851333618), (138, 0.5662548542022705), (372, 0.5492010712623596), (4, 0.5403856635093689), (559, 0.5359155535697937), (456, 0.5317966341972351)]\n\nTop 5\n the black dahlia\n what women want\n midnight express\n the getaway\n the salton sea\n\n('halloween h20: 20 years later', 126, 0.4083528518676758) \n\n"
     ]
    }
   ],
   "source": [
    "# Two characters from the same movie \n",
    "display_character_similarity(1220, True)\n",
    "display_character_similarity(1223, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : HAN\n ID : m529\n Movie : star wars\n[(92, 0.7802433967590332), (602, 0.6923903822898865), (85, 0.6741838455200195), (60, 0.658081591129303), (501, 0.6443480849266052), (460, 0.6412927508354187), (110, 0.6304922103881836), (64, 0.6292725205421448), (270, 0.6260251998901367), (448, 0.6246729493141174)]\n\nTop 5\n house of 1000 corpses\n what women want\n hellbound: hellraiser ii\n fear and loathing in las vegas\n the salton sea\n\n('star wars', 480, 0.20733563601970673) \n\nCharacter : LUKE\n ID : m529\n Movie : star wars"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[(92, 0.938231348991394), (460, 0.6798879504203796), (184, 0.6715690493583679), (64, 0.6685425639152527), (217, 0.6623952984809875), (501, 0.6532403230667114), (148, 0.6326410174369812), (440, 0.6106000542640686), (538, 0.6011205911636353), (371, 0.5948300957679749)]\n\nTop 5\n house of 1000 corpses\n a nightmare on elm street part 2: freddy's revenge\n slither\n friday the 13th\n there's something about mary\n\n('star wars', 571, -0.07022307068109512) \n\nCharacter : VADER\n ID : m529\n Movie : star wars\nTest Document (7827): «enough already know about the data you ve intercepted but its too late whatever information you ve gathered will be destroyed you will come to know such suffering as only the master of the bogan force can provide you ll get no information from me you have no authority the council can hold me it appears your ship had an accident will see to it that your death is duely reported there will be no one to save you this time the death star has become operational there is no force in the universe that can stop us now they ll find its weakness it too late we already tested it on organa major it appears your data never got through no it would be much easier if you were to tell us where the outposts are otherwise we ll be forced to destroy every suspicious system what waste»\n\n[(356, 0.7823379635810852), (501, 0.6750727891921997), (270, 0.6629260778427124), (206, 0.6602515578269958), (602, 0.6579404473304749), (258, 0.6495059132575989), (357, 0.6229392290115356), (456, 0.6105529069900513), (394, 0.609323263168335), (496, 0.6072307825088501)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTop 5\n the adventures of ford fairlane\n the salton sea\n the black dahlia\n the rock\n what women want\n\n('star wars', 591, 0.04749935865402222) \n\nCharacter : BURKE\n ID : m15\n Movie : aliens\n[(118, 0.9850348234176636), (493, 0.7783792018890381), (159, 0.7692041397094727), (608, 0.7578772902488708), (340, 0.7540571689605713), (466, 0.7441763877868652), (480, 0.7358413934707642), (113, 0.7269444465637207), (164, 0.7138222455978394), (328, 0.6932591199874878)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTop 5\n legend\n romeo and juliet\n pirates of the caribbean\n willow\n excalibur\n\n('aliens', 178, 0.2509397864341736) \n\n"
     ]
    }
   ],
   "source": [
    "# compare results from three characters that have conversations in a movie and a random character\n",
    "# Star wars : Hans, Luke and Vader\n",
    "# u7821 +++$+++ HAN +++$+++ m529\n",
    "display_character_similarity(7821, False)\n",
    "\n",
    "# u7824 +++$+++ LUKE +++$+++ m529\n",
    "display_character_similarity(7824, False)\n",
    "\n",
    "# u7827 +++$+++ VADER\n",
    "display_character_similarity(7827, True)\n",
    "\n",
    "# random character from test corpus\n",
    "display_character_similarity(random.randint(0, len(test_corpus)), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : PETER\n ID : m367\n Movie : get carter\nTest Document (5519): «gerald phoned us in the middle of the night said he heard you ve been making nuisance of yourself we ve got to take you back to london he said it be doing him big favour we know why you re all steamed up and so do gerald and sid but they have to be diplomatic put it away jack you know you won use it the gun he means gerald wants to see him first shut up»\n\n[(602, 0.7370354533195496), (270, 0.7155796885490417), (484, 0.6413251161575317), (459, 0.6298543214797974), (456, 0.6193528771400452), (486, 0.6151827573776245), (521, 0.6123079657554626), (85, 0.5797296166419983), (359, 0.5704122185707092), (338, 0.5603929162025452)]\n\nTop 5\n what women want\n the black dahlia\n vampyr\n the nightmare before christmas\n the negotiator\n\n('get carter', 166, 0.4120137393474579) \n\nCharacter : CON\n ID : m367\n Movie : get carter\nTest Document (5508): «gerald phoned us in the middle of the night said he heard you ve been making nuisance of yourself we ve got to take you back to london he said it be doing him big favour we know why you re all steamed up and so do gerald and sid but they have to be diplomatic put it away jack you know you won use it the gun he means gerald wants to see him first shut up»\n\n[(602, 0.7535027861595154), (270, 0.7297297120094299), (486, 0.673477828502655), (510, 0.6571714878082275), (95, 0.6280746459960938), (600, 0.6111929416656494), (138, 0.6071169376373291), (338, 0.6028121113777161), (484, 0.6015593409538269), (459, 0.5691995620727539)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTop 5\n what women want\n the black dahlia\n quantum project\n seven days to live\n i am legend\n\n('get carter', 171, 0.42591947317123413) \n\n"
     ]
    }
   ],
   "source": [
    "# two characters that only have conversations with each other so they have identical words in their document\n",
    "display_character_similarity(5519, True)\n",
    "display_character_similarity(5508, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : PAPAGENO\n ID : m16\n Movie : amadeus\nTest Document (259): «here am my angel what who the devil are you ve taken pity on you my angel heard your wish oh well thank you how wonderful some people get all the luck now you ve got to promise me faithfully you ll remain true to me forever then you ll see how tenderly your little birdie will love you can wait well promise then what do you mean now of course now right away before get any older well don know mean you re delicious delightful delectable little bird but don you think you might be just little tough oh tender enough for you my boy tender enough for you»\n\n[(270, 0.6591387987136841), (602, 0.647212564945221), (369, 0.6006808876991272), (364, 0.5874727964401245), (484, 0.5859410166740417), (203, 0.5789071917533875), (609, 0.5529367923736572), (456, 0.5523012280464172), (389, 0.546088695526123), (95, 0.5448217391967773)]\n\nTop 5\n the black dahlia\n what women want\n the godfather: part ii\n gandhi\n vampyr\n\n('amadeus', 160, 0.3993019461631775) \n\nCharacter : UGLY OLD WOMAN\n ID : m16\n Movie : amadeus\nTest Document (265): «here am my angel what who the devil are you ve taken pity on you my angel heard your wish oh well thank you how wonderful some people get all the luck now you ve got to promise me faithfully you ll remain true to me forever then you ll see how tenderly your little birdie will love you can wait well promise then what do you mean now of course now right away before get any older well don know mean you re delicious delightful delectable little bird but don you think you might be just little tough oh tender enough for you my boy tender enough for you»\n\n[(270, 0.7693307995796204), (369, 0.6474022269248962), (602, 0.6175506711006165), (203, 0.6081627607345581), (484, 0.5984232425689697), (372, 0.5828826427459717), (434, 0.5708822011947632), (146, 0.5698922872543335), (85, 0.5528475046157837), (456, 0.5513765811920166)]\n\nTop 5\n the black dahlia\n the godfather: part ii\n what women want\n the godfather\n vampyr\n\n('amadeus', 220, 0.37010979652404785) \n\n"
     ]
    }
   ],
   "source": [
    "# two characters that only have conversations with each other so they have identical words in their document\n",
    "display_character_similarity(259, True)\n",
    "display_character_similarity(265, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Doc2Vec algorithm starts by giving distinct document-IDs an initial random vector; also most training modes include some randomized steps. So even identical runs-of-words won't necessarily result in identically-trained vectors. Rather, they'll tend to become closer over training – perhaps arbitrarily close with enough passes, but never identical. - https://groups.google.com/forum/#!topic/gensim/LLmPa4LECXs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}